<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'G-NRZJLJCSH6');
    </script>

    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.6">
    <title>BFCL V4 Agentic [Part 3 ‚Äì Evaluating Format Sensitivity for Tool Calls]</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="../assets/css/blog.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="../assets/css/api-explorer.css">
    <link rel="stylesheet" href="../assets/css/common-styles.css">
    <link rel="stylesheet" href="../assets/css/Highlight-Clean-leaderboard.css">
    <link rel="stylesheet" href="../assets/css/model_info_dashboard.css">
    <link rel="stylesheet" href="../assets/css/contact.css">

    <style>
        .category-container {
            margin-bottom: 60px;
        }

        .category-title {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 20px;
            text-align: center;
        }

        .plots-container {
            display: flex;
            justify-content: space-between;
        }

        .plot {
            width: 49%;
            height: 450px;
            aspect-ratio: 1 / 1;
        }

        @media (max-width: 1000px) {
            .plots-container {
                flex-direction: column;
            }

            .plot {
                width: 100%;
                margin-bottom: 40px;
            }
        }

        /* Bars to separate titles in nav bar */
        .navbar a:not(:last-child)::after {
            content: "|";
            margin: 0 10px;
            color: #000;
        }

        .code-toggle {
            font-weight: bold;
            color: #0056b3;
            cursor: pointer;
            margin: 20px 0;
        }

        pre:not(#citation_block) {
            font-family: "Courier New", Courier, monospace;
            background-color: #f4f4f4;
            border-left: 5px solid #0056b3;
            padding: 15px;
            margin-top: 5px;
            overflow: auto;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .code-toggle:hover {
            text-decoration: underline;
        }

        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }

        table,
        th,
        td {
            border: 1px solid #ddd;
        }

        th,
        td {
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }

        .scenario-box {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
        }

        .scenario-title {
            font-weight: bold;
            color: #495057;
            margin-bottom: 10px;
        }

        .analysis-section {
            background-color: #e9ecef;
            padding: 15px;
            border-radius: 5px;
            margin-top: 15px;
        }

        .takeaway-section {
            background-color: #d1ecf1;
            padding: 15px;
            border-radius: 5px;
            margin-top: 10px;
            border-left: 4px solid #bee5eb;
        }

        .image-container {
            text-align: center;
            margin: 20px 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
        }

        figcaption {
            font-style: italic;
            color: #666;
            margin-top: 10px;
            text-align: center;
        }

        .box-index {
            position: fixed;
            top: 50%;
            left: 0px;
            transform: translateY(-50%);
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            max-width: 150px;
        }

        .box-index h3 {
            font-size: 1.2em;
            margin-bottom: 10px;
        }

        .box-index ul {
            list-style-type: disc;
            padding: 0;
        }

        .box-index ul li {
            margin-bottom: 10px;
        }

        .box-index ul li a {
            text-decoration: none;
            color: #333;
        }

        .box-index ul li a:hover {
            color: #1e90ff;
        }

        .more-blogs .sub-menu {
            display: none;
        }

        .more-blogs .sub-menu.expanded {
            display: block;
            max-height: 200px;
            overflow-y: auto;
        }

        .more-blogs .sub-menu li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
        }

        .more-blogs .sub-menu li:last-child {
            border-bottom: none;
        }

        .more-blogs .caret {
            transition: transform 0.3s ease-in-out;
            display: inline-block;
            transform: rotate(0deg);
            font-size: 12px;
        }

        .more-blogs.expanded .caret {
            transform: rotate(90deg);
        }

        @media screen and (max-width: 1000px) {
            .box-index {
                display: none;
            }
        }
    </style>
</head>

<body>
    <!-- Navigation Bar -->
    <div class="navbar">
        <a href="/index.html">Home</a>
        <a href="/blog.html">Blogs</a>
        <a href="/leaderboard.html">BFCL Leaderboard</a>
    </div>

    <div class="highlight-clean-blog" style="padding-bottom: 10px">
        <h1 class="text-center" style="padding-bottom: 10px">
            ü¶ç Gorilla: Large Language Model Connected with Massive APIs
        </h1>

        <div class="box-index">
            <h3>BFCL V4 Agentic [Part 3 ‚Äì Format Sensitivity]</h3>
            <ul>
                <li><a href="#intro">Introduction</a></li>
                <li><a href="#prompt-variation">Prompt Variation Construction</a></li>
                <li><a href="#test-selection">Test Entry Selection</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#failure-modes">Discussion of Failure Modes</a></li>
                <li class="more-blogs">
                    <a href="javascript:void(0);" onclick="toggleMoreBlogs()"
                        >More Blogs <span class="caret">&#9654;</span></a
                    >
                    <ul class="sub-menu">
                        <li>
                            <a href="16_bfcl_v4_memory.html">BFCL V4 Memory</a>
                        </li>
                        <li>
                            <a href="15_bfcl_v4_web_search.html">BFCL V4 Web Search</a>
                        </li>
                        <li>
                            <a href="13_bfcl_v3_multi_turn.html">BFCL V3 Multi-Turn</a>
                        </li>
                        <li><a href="12_bfcl_v2_live.html">BFCL V2 Live Dataset</a></li>
                        <li>
                            <a href="8_berkeley_function_calling_leaderboard.html"
                                >BFCL V1</a
                            >
                        </li>
                        <li>
                            <a href="7_open_functions_v2.html">Gorilla OpenFunctions-v2</a>
                        </li>
                        <li><a href="6_api_zoo.html">The API Zoo</a></li>
                        <li><a href="5_how_to_gorilla.html">How to Use Gorilla</a></li>
                        <li><a href="4_open_functions.html">Gorilla OpenFunctions</a></li>
                    </ul>
                </li>
            </ul>
        </div>

        <div class="blog-container">
            <div class="blog-post">
                <h2 class="blog-title">
                    BFCL V4 Agentic [Part 3 ‚Äì Evaluating Format Sensitivity for Tool Calls]
                </h2>

                <div class="col-md-12">
                    <h4 class="text-center" style="margin: 0px">
                        <p></p>
                        <a class="author" href="https://gorilla.cs.berkeley.edu/">BFCL Team</a>
                        <p></p>
                    </h4>
                </div>

                <b
                    ><i style="font-size: 1em"
                        >Release date: 2025-07-17. Last updated: 2025-07-17.
                        <a
                            href="https://github.com/ShishirPatil/gorilla/blob/main/berkeley-function-call-leaderboard/CHANGELOG.md"
                            >[Change Log]</a
                        ></i
                    ></b
                >

                <div>
                    <br />
                    <p>
                        <strong>
                            With function-calling being the building blocks of Agents, the
                            Berkeley Function-Calling Leaderboard (BFCL) V4 presents a
                            holistic agentic evaluation for LLMs. BFCL V4 includes web search (part‚Äë1), 
                            memory (part-2), and format sensitivity (detailed in this blog). Together, 
                            the ability to web search, read and write from memory, and the ability to 
                            invoke functions in different languages present the building blocks for the 
                            exciting and extremely challenging avenues that power agentic LLMs today 
                            from deep-research, to agents for coding and law.
                        </strong>
                    </p>

                    <p>
                        <strong>
                            If you're new to function calling, be sure to check out our
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html"
                                >earlier blog posts</a
                            >
                            for more background. In
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html"
                                >BFCL V1</a
                            >, we introduced expert-curated single-turn, simple, parallel,
                            and multiple function calling.
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/12_bfcl_v2_live.html"
                                >BFCL V2</a
                            >
                            introduced community ‚Äì hobbyists and enterprise ‚Äì contributed
                            functions.
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html"
                                >BFCL V3</a
                            >
                            introduced multi-turn and multi-step function calling that let
                            models interact with the user, including ability to go
                            back-and-forth asking clarifying questions and refining the
                            approach. Throughout, BFCL relies on AST (Abstract Syntax
                            Tree) based, or state-transition based verification ensuring
                            determinism and minimal fluctuations as you evaluate your models
                            and applications.
                        </strong>
                    </p>

                    <h3>Quick Links</h3>
                    <ul>
                        <li>
                            BFCL Leaderboard:
                            <a href="https://gorilla.cs.berkeley.edu/leaderboard.html"
                                >Website</a
                            >
                        </li>
                        <li>
                            BFCL Dataset:
                            <a
                                href="https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard/data"
                                >HuggingFace Dataset ü§ó</a
                            >
                        </li>
                        <li>
                            Reproducibility:
                            <a
                                href="https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard"
                                >GitHub Code</a
                            >
                        </li>
                        <li>
                            BFCL v1:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html"
                                >Simple, Parallel, and Multiple Function Call eval with AST</a
                            >
                        </li>
                        <li>
                            BFCL v2:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/12_bfcl_v2_live.html"
                                >Enterprise and OSS‚Äëcontributed Live Data</a
                            >
                        </li>
                        <li>
                            BFCL v3:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html"
                                >Multi‚ÄëTurn & Multi‚ÄëStep Function Calling Evaluation</a
                            >
                        </li>
                        <li>
                            BFCL v4 Agentic:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/15_bfcl_v4_web_search.html"
                                >Part 1 Web Search</a
                            >
                        </li>
                        <li>
                            BFCL v4 Agentic:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/16_bfcl_v4_memory.html"
                                >Part 2 Memory</a
                            >
                        </li>
                        <li>
                            BFCL v4 Agentic:
                            <a
                                href="https://gorilla.cs.berkeley.edu/blogs/17_bfcl_v4_prompt_variation.html"
                                >Part 3 Format Sensitivity</a
                            >
                        </li>
                    </ul>

                    <p>
                        In our past releases, we are encouraged by the community's deep
                        appreciation of the insights across different models. So, this
                        time we have divided our BFCL V4 release blogs into three parts to
                        address the technical complexities, and more importantly share
                        many more interesting insights.
                    </p>

                    <hr />

                    <h3 id="intro">Introduction</h3>
                    <p>
                        Function calling, or tool use, has emerged as a prominent area of 
                        research with widespread practical applications. Furthermore, agentic 
                        tasks that require function calls in real-world scenarios often come 
                        with many variations in format - whether the model is expected to make 
                        function calls in Python or JSON, available functions are described in 
                        Python or XML, or other variations. As format conversions can be hard 
                        to implement and intractable for large-scale agentic applications, 
                        assessing the format sensitivity of LLMs' function calling capabilities 
                        becomes an essential task for evaluation. However, current benchmarks 
                        on function calling use a single prompt format for all models and 
                        queries, that is, with the same language, same requirements for syntax, 
                        same format of provided functions, etc. To address this gap, the BFCL 
                        V4 Agentic Format Sensitivity provides a systematic evaluation framework 
                        for assessing the format sensitivity of the function calling capabilities 
                        of large language models.
                    </p>

                    <p>
                        The core premise of BFCL V4 Agentic Format Sensitivity is this: for 
                        any given query, a model should produce the correct output regardless 
                        of variations in input format‚Äî
                    </p>

                    <p>
                        To systematically explore model behaviors and assess their format 
                        sensitivity under this premise, we create variations of prompts based 
                        on the following five key dimensions (detailed in the following section):
                    </p>

                    <ul>
                        <li><strong>Return format:</strong> syntax requirements which the model should follow when giving function calls, (e.g., Python, JSON).</li>
                        <li><strong>Function documentation format:</strong> the syntax used to describe available functions (e.g., Python, XML).</li>
                        <li><strong>Tool calling tag:</strong> whether the model should use an additional, XML-style tag to enclose the outputted function calls.</li>
                        <li><strong>Prompt format:</strong> presentation of prompts in plain text vs. Markdown.</li>
                        <li><strong>Prompt style:</strong> variations in tone and instructional phrasing</li>
                    </ul>

                    <p>
                        In this blog, we explain the construction of prompt variations and the 
                        selection of test entries. We then present comprehensive results on 39 
                        evaluated models. Additionally, we discuss common trends of performance, 
                        common failure modes across models, and specific failure modes by model.
                    </p>

                    <hr />

                    <h3 id="prompt-variation">Prompt variation construction</h3>
                    <p>
                        To construct the prompt variations, we build upon the original Berkeley 
                        Function Calling Leaderboard (BFCL V1) default system prompt by 
                        parameterizing key components as listed below:
                    </p>

                    <table>
                        <thead>
                            <tr>
                                <th>Component Name</th>
                                <th>Possible Values</th>
                                <th>Descriptions</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>return_format</td>
                                <td>"python", "json", "verbose_xml", "concise_xml"</td>
                                <td>Specifies the syntax the model should use to format the function call outputs.</td>
                            </tr>
                            <tr>
                                <td>function_doc_format</td>
                                <td>"python", "xml", "json"</td>
                                <td>Controls how function documentation is presented to the model.</td>
                            </tr>
                            <tr>
                                <td>has_tool_call_tag</td>
                                <td>True, False</td>
                                <td>Whether to wrap function outputs in &lt;TOOLCALL&gt;...&lt;/TOOLCALL&gt; tags.</td>
                            </tr>
                            <tr>
                                <td>prompt_format</td>
                                <td>"plaintext", "markdown"</td>
                                <td>Determines the overall format of the system prompt (plain text or structured with headers).</td>
                            </tr>
                            <tr>
                                <td>prompt_style</td>
                                <td>"classic", "experimental"</td>
                                <td>Defines the tone and instruction style.</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>
                        These elements were dynamically assembled, allowing us to precisely 
                        control variations across all combinations of the parameters. For our 
                        experiments, we consider all possible combinations of `return_format`, 
                        `has_tool_call_tag`, and `function_doc_format`. Additionally, we vary 
                        the original system prompt by independently setting `prompt_format="markdown"` 
                        and `prompt_style="experimental"`, resulting in a total of 26 distinct 
                        variations.
                    </p>

                    <hr />

                    <h3 id="test-selection">Test entry selection</h3>
                    <p>
                        To assess model behaviors across prompt variations, we select a total 
                        of 200 single-turn test entries from the simple, multiple, parallel, 
                        and multiple parallel components of both expert-curated and live (i.e., 
                        community contributed) datasets of BFCL V2, which adds up to 2351 entries. 
                        Test entries from the multi-turn, java, javascript, and hallucination 
                        measurement categories are not considered for this study, as model 
                        behaviors under prompt and format variations should already be demonstrable 
                        on more basic single-turn test settings.
                    </p>

                    <p>
                        To demonstrate the validity of our test entry selection, we further test 
                        20 models both on all the 2351 entries and on the selected entries across 
                        all constructed prompt variations. (We could not test all models on all 
                        entries due to budget constraints. All our code is open-sourced!) As 
                        shown in Figure 1, model performance on all test entries and on selected 
                        entries show strong linear relationship, which implies that the selected 
                        200 entries are sufficient for evaluating the format sensitivity of 
                        models' function calling capabilities.
                    </p>

                    <p>
                        Additionally, we give the breakdown of the selected 200 entries in the 
                        following table:
                    </p>

                    <table>
                        <thead>
                            <tr>
                                <th>Test category</th>
                                <th>Number of selected entries</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>simple</td>
                                <td>30</td>
                            </tr>
                            <tr>
                                <td>parallel</td>
                                <td>15</td>
                            </tr>
                            <tr>
                                <td>multiple</td>
                                <td>15</td>
                            </tr>
                            <tr>
                                <td>parallel_multiple</td>
                                <td>15</td>
                            </tr>
                            <tr>
                                <td>live_simple</td>
                                <td>24</td>
                            </tr>
                            <tr>
                                <td>live_parallel</td>
                                <td>86</td>
                            </tr>
                            <tr>
                                <td>live_multiple</td>
                                <td>6</td>
                            </tr>
                            <tr>
                                <td>live_parallel_multiple</td>
                                <td>9</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 20px 0">
                        <img
                            src="../assets/img/blog_post_17_figure1.png"
                            alt="Comparison of model accuracy on 200 selected entries versus all entries"
                            style="max-width: 100%; height: auto"
                        />
                    </div>
                    <p
                        style="
                            text-align: center;
                            font-style: italic;
                            color: #666;
                            margin-top: 10px;
                        "
                    >
                        Figure 1. Comparison of model accuracy on 200 selected entries versus 
                        all entries. Each dot represents a specific model and a specific prompt 
                        variation. Results indicate a strong correlation between performance on 
                        the sampled subset and the full dataset.
                    </p>

                    <hr />

                    <h3 id="results">Results</h3>
                    <p>
                        We present the complete heatmap of tested models in Figure 2. We also 
                        discuss in this section some general trends across models regarding the 
                        prompt variations.
                    </p>

                    <div style="text-align: center; margin: 20px 0">
                        <img
                            src="../assets/img/blog_post_17_figure2.png"
                            alt="Heatmap for all tested models across all prompt variation configurations"
                            style="max-width: 100%; height: auto"
                        />
                    </div>
                    <p
                        style="
                            text-align: center;
                            font-style: italic;
                            color: #666;
                            margin-top: 10px;
                        "
                    >
                        Figure 2. Heatmap for all tested models across all prompt variation 
                        configurations. The notations of prompt variations are in the format 
                        of `{function_doc_format}->{return_format},{has_tool_call_tag}`. For 
                        the variations with `prompt_format="markdown"` or `prompt_style="experimental"`, 
                        we append in the end `"md"` or `"exp"`.
                    </p>

                    <h4>Changing function call return format</h4>
                    <p>
                        Averaged across all test categories and prompt variation settings for 
                        each return format, we observe a general trend‚Äîparticularly for smaller 
                        models‚Äîwhere performance is higher when the model is prompted to return 
                        function calls in Python or JSON format, compared to either of the XML 
                        formats. Notably, for the Claude family models and some function-calling 
                        models like watt-tool and CoALM, even large LLMs (watt-tool-70B, 
                        claude-3.7-sonnet) show significant performance drops when return format 
                        is in XML format.
                    </p>

                    <div style="text-align: center; margin: 20px 0">
                        <img
                            src="../assets/img/blog_post_17_figure3.png"
                            alt="Comparison of model performance across return format configurations - Python"
                            style="max-width: 100%; height: auto"
                        />
                    </div>

                    <div style="text-align: center; margin: 20px 0">
                        <img
                            src="../assets/img/blog_post_17_figure4.png"
                            alt="Comparison of model performance across return format configurations - JSON"
                            style="max-width: 100%; height: auto"
                        />
                    </div>

                    <div style="text-align: center; margin: 20px 0">
                        <img
                            src="../assets/img/blog_post_17_figure5.png"
                            alt="Comparison of model performance across return format configurations - XML"
                            style="max-width: 100%; height: auto"
                        />
                    </div>
                    <p
                        style="
                            text-align: center;
                            font-style: italic;
                            color: #666;
                            margin-top: 10px;
                        "
                    >
                        Comparison of model performance across return format configurations. 
                        For each return format, we averaged accuracies from all prompt variations 
                        with that format, excluding those with `prompt_format="markdown"` or 
                        `prompt_style="experimental"`. Results indicate that Python and JSON 
                        return formats generally outperform both XML formats.
                    </p>

                    <h4>Other findings</h4>
                    <p>
                        Additionally, we observed that several models that are trained specifically 
                        for tool use show significant drops (even to 0 accuracies) when we change 
                        the return format or ask for tool call tags. For instance, watt-tool-70B 
                        is unable to correctly output JSON format function calls, and gives Python 
                        style function calls instead; CoALM-70B cannot correctly use tool call 
                        tags, and show near-zero performance even if we simply add tool call tag 
                        requirements to the original BFCL system prompt. More details of specific 
                        failure cases can be found in Section 5.2.
                    </p>

                    <hr />

                    <h3 id="failure-modes">Discussion of failure modes</h3>

                    <h4>Common Failure Modes</h4>
                    <ul>
                        <li><strong>Return format xml + function doc format python:</strong> fail to adhere to parameter type instructions (e.g. asked to write "integer", but model gives "int")</li>
                    </ul>

                    <div class="scenario-box">
                        <div class="scenario-title">
                            Example #1: Parameter Type Mismatch
                        </div>
                        <p><strong>ID and variation:</strong> simple_19, py->verbose_xml, has tool tag</p>
                        <p><strong>Prompt:</strong></p>
                        <pre><code>system:
You are an expert in composing functions.You are given a question and a set of possible functions. Based on the question, you will need to make one or more function/tool calls to achieve the purpose. If none of the functions can be used, point it out. If the given question lacks the parameters required by the function, also point it out.

You should only return the function calls in the <TOOLCALL> section. If you decide to invoke any of the function(s), you MUST put it in the format of <TOOLCALL><functions><function name="func_name1"><params><param name="param1" value="value1" type="type1"/><param name="param2" value="value2" type="type2"/>...</params></function><function name="func_name2"><param name="param3" value="value3" type="type3"/></function></functions></TOOLCALL>. The type fields of the parameters in your function calls must be one of: string, integer, float, boolean, array, dict, or tuple. You SHOULD NOT include any other text in the response.

At each turn, you should try your best to complete the tasks requested by the user within the current turn. Continue to output functions to call until you have fulfilled the user's request to the best of your ability. Once you have no more functions to call, the system will consider the current turn complete and proceed to the next turn or task.

Here is a list of functions in python format that you can invoke.
# Function: math.gcd
    """
    Compute the greatest common divisor of two numbers

    Args:
        num1 (int): The first number.
        num2 (int): The second number.
    """

user:
Calculate the greatest common divisor of two numbers: 40 and 50</code></pre>

                        <p><strong>Incorrect output:</strong> (from claude-3.7-sonnet-20250219)</p>
                        <pre><code>&lt;TOOLCALL&gt;
&lt;functions&gt;
&lt;function name="math.gcd"&gt;
&lt;params&gt;
&lt;param name="num1" value="40" type="int"/&gt;
&lt;param name="num2" value="50" type="int"/&gt;
&lt;/params&gt;
&lt;/function&gt;
&lt;/functions&gt;
&lt;/TOOLCALL&gt;</code></pre>

                        <p><strong>Correct output example:</strong> (from DeepSeek-R1)</p>
                        <pre><code>&lt;TOOLCALL&gt;&lt;functions&gt;&lt;function name="math.gcd"&gt;&lt;params&gt;&lt;param name="num1" value="40" type="integer"/&gt;&lt;param name="num2" value="50" type="integer"/&gt;&lt;/params&gt;&lt;/function&gt;&lt;/functions&gt;&lt;/TOOLCALL&gt;</code></pre>
                    </div>

                    <ul>
                        <li><strong>Return format xml:</strong> asked model to put <strong>all</strong> function calls within &lt;functions&gt;&lt;/functions&gt;, but model output wraps <strong>each</strong> function call with &lt;functions&gt;&lt;/functions&gt; (also a similar case, if has tool call tag, wraps each function call with &lt;TOOLCALL&gt;&lt;/TOOLCALL&gt;)</li>
                    </ul>

                    <div class="scenario-box">
                        <div class="scenario-title">
                            Example #2: Incorrect XML Structure
                        </div>
                        <p><strong>ID and variation:</strong> parallel_36, {json}->{verbose}, False</p>
                        <p><strong>Prompt:</strong></p>
                        <pre><code>system:
You are an expert in composing functions.You are given a question and a set of possible functions. Based on the question, you will need to make one or more function/tool calls to achieve the purpose. If none of the functions can be used, point it out. If the given question lacks the parameters required by the function, also point it out.

You should only return the function calls in your response.

If you decide to invoke any of the function(s), you MUST put it in the format of <functions><function name="func_name1"><params><param name="param1" value="value1" type="type1"/><param name="param2" value="value2" type="type2"/>...</params></function><function name="func_name2"><param name="param3" value="value3" type="type3"/></function></functions>. The type fields of the parameters in your function calls must be one of: string, integer, float, boolean, array, dict, or tuple. You SHOULD NOT include any other text in the response.

At each turn, you should try your best to complete the tasks requested by the user within the current turn. Continue to output functions to call until you have fulfilled the user's request to the best of your ability. Once you have no more functions to call, the system will consider the current turn complete and proceed to the next turn or task.

Here is a list of functions in json format that you can invoke.

[{'name': 'paint_color_mixture', 'description': 'Gives a combination of primary colors to mix for creating a certain color. This function requires type of paint and color. Note that the provided function is in Python 3 syntax.', 'parameters': {'type': 'dict', 'properties': {'paint_type': {'type': 'string', 'description': 'The type of paint (Watercolor, Oil, Acrylic).'}, 'color': {'type': 'string', 'description': 'The color to be produced from the mixture.'}}, 'required': ['paint_type', 'color']}}]

user:
Using watercolor, what combination of colors should I mix to get the color magenta and what quantity for each color? Also, I want to know how to get color navy by using acrylic paint and their respective quantities.</code></pre>

                        <p><strong>Incorrect output example:</strong> (from claude-3.7-sonnect-20250219)</p>
                        <pre><code>&lt;functions&gt;
&lt;function name="paint_color_mixture"&gt;
&lt;params&gt;
&lt;param name="paint_type" value="Watercolor" type="string"/&gt;
&lt;param name="color" value="magenta" type="string"/&gt;
&lt;/params&gt;
&lt;/function&gt;
&lt;/functions&gt;

&lt;functions&gt;
&lt;function name="paint_color_mixture"&gt;
&lt;params&gt;
&lt;param name="paint_type" value="Acrylic" type="string"/&gt;
&lt;param name="color" value="navy" type="string"/&gt;
&lt;/params&gt;
&lt;/function&gt;
&lt;/functions&gt;</code></pre>

                        <p><strong>Correct output example:</strong> (from mistral-large-2411)</p>
                        <pre><code>&lt;functions&gt;
&lt;function name="paint_color_mixture"&gt;
&lt;params&gt;
&lt;param name="paint_type" value="Watercolor" type="string"/&gt;
&lt;param name="color" value="magenta" type="string"/&gt;
&lt;/params&gt;
&lt;/function&gt;
&lt;function name="paint_color_mixture"&gt;
&lt;params&gt;
&lt;param name="paint_type" value="Acrylic" type="string"/&gt;
&lt;param name="color" value="navy" type="string"/&gt;
&lt;/params&gt;
&lt;/function&gt;
&lt;/functions&gt;</code></pre>
                    </div>

                    <hr />

                    <p>
                        We hope you enjoyed this blog post. We would love to hear from you
                        on <a href="https://discord.gg/grXXvj9Whz">Discord</a>,
                        <a
                            href="https://twitter.com/shishirpatil_/status/1661780076277678082"
                            >Twitter (#GorillaLLM)</a
                        >, and
                        <a href="https://github.com/ShishirPatil/gorilla/">GitHub</a>.
                    </p>

                    <h4>If you would like to cite BFCL:</h4>
                    <pre id="citation_block"
                        style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
                        <code>
@inproceedings{patil2025bfcl,
  title={The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models},
  author={Patil, Shishir G. and Mao, Huanzhi and Cheng-Jie Ji, Charlie and Yan, Fanjia and Suresh, Vishnu and Stoica, Ion and E. Gonzalez, Joseph},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025},
}
                        </code>
                    </pre>
                </div>
            </div>
        </div>
    </div>

    <script>
        function toggleMoreBlogs() {
            var submenu = document.querySelector(".sub-menu");
            var caret = document.querySelector(".caret");
            if (submenu.style.display === "none" || submenu.style.display === "") {
                submenu.style.display = "block";
                caret.innerHTML = "&#9660;";
            } else {
                submenu.style.display = "none";
                caret.innerHTML = "&#9654;";
            }
        }

        // Initially hide the submenu
        document.addEventListener("DOMContentLoaded", function () {
            var submenu = document.querySelector(".sub-menu");
            if (submenu) {
                submenu.style.display = "none";
            }
        });
    </script>
</body>
</html>
